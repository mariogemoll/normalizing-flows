{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe28007-af47-46b3-8980-0ede27f6dac1",
   "metadata": {},
   "source": [
    "# Normalizing Flows\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mariogemoll/normalizing-flows/blob/main/py/normalizing-flows.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddc82f-e071-4dea-8d24-6a5e272e7afa",
   "metadata": {},
   "source": [
    "Let's create a normalizing flow model for the moons dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51457f2c-b981-44d6-b036-31617c140bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import display\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "def sample_from_moons(n):\n",
    "    moons = make_moons(n_samples=n, noise=0.05)[0].astype(np.float32)\n",
    "    return torch.from_numpy(moons)\n",
    "\n",
    "X = sample_from_moons(10000)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38830761-2efc-4e48-9140-dcbb71c30e9b",
   "metadata": {},
   "source": [
    "The model consists of 8 coupling layers, each of them modifying one of the two dimensions in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab044f2-a7b8-4550-91c7-45b9bb0988c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, flip):\n",
    "        super().__init__()\n",
    "        self.flip = flip\n",
    "        hidden_dims = 24\n",
    "        self.scale_net = MLP(hidden_dims)\n",
    "        self.shift_net = MLP(hidden_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        if self.flip:\n",
    "            x1, x2 = x2, x1\n",
    "\n",
    "        s = self.scale_net(x1)\n",
    "        s = torch.tanh(s)\n",
    "        t = self.shift_net(x1)\n",
    "\n",
    "        y1 = x1\n",
    "        y2 = torch.exp(s) * x2 + t\n",
    "        log_det = s.sum(dim=1)\n",
    "\n",
    "        if self.flip:\n",
    "            y1, y2 = y2, y1\n",
    "\n",
    "        return torch.cat([y1, y2], dim=1), log_det\n",
    "\n",
    "    def inverse(self, y):\n",
    "        y1, y2 = y.chunk(2, dim=1)\n",
    "        if self.flip:\n",
    "            y1, y2 = y2, y1\n",
    "\n",
    "        s = self.scale_net(y1)\n",
    "        s = torch.tanh(s)\n",
    "        t = self.shift_net(y1)\n",
    "\n",
    "        # Inverse transform\n",
    "        x1 = y1\n",
    "        x2 = (y2 - t) * torch.exp(-s)\n",
    "        log_det = -s.sum(dim=1)\n",
    "\n",
    "        if self.flip:\n",
    "            x1, x2 = x2, x1\n",
    "\n",
    "        return torch.cat([x1, x2], dim=1), log_det\n",
    "\n",
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            CouplingLayer(i % 2 == 0)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = x.shape[0]\n",
    "        log_det = torch.zeros(m).to(device)\n",
    "        zs = [x]\n",
    "        for layer in self.layers:\n",
    "            x, layer_log_det = layer(x)\n",
    "            log_det += layer_log_det\n",
    "            zs.append(x)\n",
    "        return zs, log_det\n",
    "\n",
    "    def inverse(self, z):\n",
    "        m = z.shape[0]\n",
    "        log_det = torch.zeros(m).to(device)\n",
    "        xs = [z]\n",
    "        for layer in reversed(self.layers):\n",
    "            z, layer_log_det = layer.inverse(z)\n",
    "            log_det += layer_log_det\n",
    "            xs.append(z)\n",
    "        return xs, log_det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023e9cf-b2f1-434f-83fc-fafa48dc21f6",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12339d-0f3d-4f55-a803-78cb7a0d792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = NormalizingFlow(num_layers=8).to(device)\n",
    "optimizer = torch.optim.Adam(flow.parameters(), lr=1e-3)\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(range(1000))\n",
    "for epoch in pbar:\n",
    "    x = sample_from_moons(1024).to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    zs, log_j = flow(x)\n",
    "    z = zs[-1]\n",
    "    loss = 0.5 * torch.sum(z**2, dim=1).to(device) - log_j\n",
    "    loss = loss.mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(f'Loss: {loss.item():.2f}')\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c7c4d-4a3f-4f68-99ee-09cf059201ca",
   "metadata": {},
   "source": [
    "We can now see how the model transforms the moons data distribution into something which\n",
    "looks pretty much like a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8704b-8fad-438f-9507-f986274e0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.eval()\n",
    "X = X.to(device)\n",
    "with torch.no_grad():\n",
    "    zs, _ = flow(X)\n",
    "    z = zs[-1]\n",
    "X = X.cpu()\n",
    "z = z.cpu()\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1, alpha=0.5)\n",
    "plt.title(\"Original Data\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(z[:, 0], z[:, 1], s=1, alpha=0.5)\n",
    "plt.title(\"Transformed Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7f42c-8d4f-486e-92bb-11131229f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable JS animation in Jupyter\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "flow_outputs = [output.cpu() for output in zs]\n",
    "\n",
    "# Interpolation settings\n",
    "num_interp_frames = 10\n",
    "total_frames = (len(flow_outputs) - 1) * num_interp_frames\n",
    "\n",
    "# Precompute interpolated frames\n",
    "interp_outputs = []\n",
    "for i in range(len(flow_outputs) - 1):\n",
    "    for t in np.linspace(0, 1, num_interp_frames):\n",
    "        interpolated = (1 - t) * flow_outputs[i] + t * flow_outputs[i + 1]\n",
    "        interp_outputs.append(interpolated)\n",
    "\n",
    "# Turn off interactive mode to prevent automatic figure display\n",
    "plt.ioff()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter([], [], s=1, alpha=0.5)\n",
    "\n",
    "x_min, x_max = (\n",
    "    min(d[:, 0].min() for d in flow_outputs),\n",
    "    max(d[:, 0].max() for d in flow_outputs)\n",
    ")\n",
    "y_min, y_max = (\n",
    "    min(d[:, 1].min() for d in flow_outputs),\n",
    "    max(d[:, 1].max() for d in flow_outputs)\n",
    ")\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "def update(frame):\n",
    "    data = interp_outputs[frame]\n",
    "    sc.set_offsets(data)\n",
    "    return sc,\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, update, frames=total_frames, interval=50, blit=False\n",
    ")\n",
    "\n",
    "# Only display the animation, not the static figure\n",
    "display(anim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
